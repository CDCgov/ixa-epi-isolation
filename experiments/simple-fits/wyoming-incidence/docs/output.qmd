---
title: "Fit to Wyoming state-level hospitalization incidence data"
author: "Will Koval (AD71@cdc.gov, CDC/ORR/CFA)"
format: pdf
toc: true
number-sections: true
execute:
    warning: false
jupyter: python3
---

# Purpose

Describe the objective of the experiment

# Methods

## Data

The National Hospital Surveillance Network (NHSN) data was downloaded from the public data repository
and filtered by state to select data from Wyoming. We then filter for dates on or after September 19th, 2020,
leaving September 12th to be the day 0 of the simulation.

Synthetic population data were generated using `create_synthetic_population.R`, setting the state to `WY`
and the population size to 589,000 to reflect Wyoming's size.

## Parameters

| Parameter name | Description |
| :------------: | ----------- |
| `initial_incidence` | Initial fraction of population infectious |
| `initial_recovered` | Initial fraction of population immune to infection |
| `proportion_asymptomatic` | The fraction of new cases that will never develop symptoms |
| `relative_infectiousness_asymptomatics` | Multiplier for the relative infectiousness of asymptomatic infectious individuals compared to symptomatics |
| `SettingCategory.alpha` | Property of `SettingCategory` settings that modulates density-dependence. Options `[Home, Workplace, School, CensusTract]`. Notation $\alpha_\lambda$ for setting $\lambda$. |
| `SettingCategory.ratio` | Property of `SettingCategory` settings that determines the absolute time weight of a setting type in an itinerary. Relative to other settings. |
| `symptom_progression_library` | Rates of symptom onset and recovery for symptom categories |
| `mean_delay_to_hospitalization` | Mean time from symptom onset to hospitalization |
| `mean_duration_of_hospitalization` | Mean time that hospitalized individuals stay in the hospital before recovery | In estimated range |
| `age_groups.min` | Age group lower bound associated with hospitalization risk values |
| `age_groups.probability` | Probability that symptomatic individuals become hospitalized for a given age group |
| `infectiousness_rate_fn` | Function to determine the rate at which infecitous indivudals generate infection attempts |

### Fixed parameter values

We assume no interventions or behavioral changes affect contact rates during the outbreak calibration period.

| Parameter | Value | Source |
| :-------: | :---: | ------ |
| `initial_incidence` | 0.01 | Small initial incidence for full curve |
| `relative_infectiousness_asymptomatics` | 0.81 | Assumed from relative logVL mild:severe symptoms, Chen et al., 2021. eLife. |
| $\alpha_{\text{CensusTract}}$ | 0.0 | Assume no density-dependence in community |
| `SettingCategory.ratio` | 0.25 | All settings have equal weight |
| `symptom_progression_library` | Category-dependent Weibull | Use posteriors from viral-load isolation gudiance |
| `infectiousness_rate_fn` | Category-dependent triangle VL | Use posteriors from viral-load isolation guidance |
| `mean_delay_to_hospitalization` | 5.7 | Mean delay from Yadav et al. 2023 Am J Emerg Med |
| `mean_duration_of_hospitalization` | 8.0 | Approximated during GCM experiments using NHCS data |
| `age_groups.min` | Decile | Binned according to Hladish et al., 2024. PLOS Comp Bio |
| `age_groups.probability` | See next table | Hladish et al., 2024. PLOS Comp Bio |

Note that the ratio weight of each setting depends on the the number of `AnySettingId`s present in an individual's itinerary. For example,
if an individual goes to only `School` or `Work`, in addition to their `CensusTract` and `Home`, they would spend 1.33 times more
of their day at `Home` and in their community than someone who goes to both `School` and `Work`.

The relative infectiousness of asymptomatics is assumed to be proportional to the WT ratio of log viral load between individuals
with mild and severe symptoms, estimated to be 0.81 two days after symptom onset by Chen et al., 2021. Age and sex were National
found to be significant predictors of viral load. We assume that differences between this ratio and the relative infectiousness
of asymptomatics can be averaged out in the infectiousness rate scaling factor.

To approximate hospitalization given the onset of any symptoms, we use the deciles table from Hladish et al., 2024.

We assumed that P(hospitalization | severe symptoms) $\times$ P(severe symptoms | Age) from Hladish et al., 2024 would generate
a viable age-specific hospitalization risk table. However, our model uses P (Hospitalization | Age, symptomatic). 

| Age group | $P(H \vert \text{Age})$ |
| :-------: | :---: |
| 0-9 | 0.00495 |
| 10-19 | 0.00216 |
| 20-29 | 0.00329 |
| 30-39 | 0.00675 |
| 40-49 | 0.0117 |
| 50-59 | 0.0212 |
| 60-69 | 0.0437 |
| 70-79 | 0.0855 |
| 80+ | 0.0945 |

We assume that dividing by the point estimate of the proportion asymptomatic for the WT variant (0.45, Whitaker et al., 2022. Table S2) 
can initially approximate that value and we later fit the proportion asymptomatic with strong priors. the final values used in the
simulation are as follows:

| Age group | $P(H \vert \text{Age, symptoms})$ |
| :-------: | :---: |
| 0-9      | 0.011  |
| 10-19    | 0.0048 |
| 20-29    | 0.0073 |
| 30-39    | 0.015  |
| 40-49    | 0.026  |
| 50-59    | 0.047  |
| 60-69    | 0.097  |
| 70-79    | 0.19   |
| 80+      | 0.21   |

### Fitted parameter values

| Parameter | Prior | Source |
| :-------: | :---: | ------ |
| $\alpha_\text{Home}$ | Uniform(0.0, 0.2) | uninformative |
| $\alpha_\text{Work}$ | Uniform(0.0, 0.2) | uninformative |
| $\alpha_\text{Sch}$ | Uniform(0.0, 0.2) | uninformative |
| `initial_recovered` | Beta(5, 15) | Assumed partial protection in summer wave |
| `infectiousness_rate_fn.scale` | Uniform(0.0, 0.2) | uninformative |
| `proportion_asymptomatic` | Beta(45, 55) | WT variant point estimate (0.45) with wider variance, Whitaker et al. 2022 Nat Comm. |

The point estimate for the alpha variant wave, which corresponds to the timing of the data we filter from NHSN, has narrow margins
(0.45, 95% CI: 0.43, 0.46). We increase the variance to account for reasonable differences between UK and US populations, as well as
to allow for the appropriate calibration of IHR since we fixed age-group hospitalization risks.

We use Gaussian noise to perturb parameter sets across ABC SMC steps

| Parameter | Perturbation |
| :-------: | :---: |
| `infectiousness_rate_fn.scale` | Norm(0.0, 0.01) |
| `proportion_asymptomatic` | Norm(0.0, 0.02) |
| `initial_recovered` | Norm(0.0, 0.02) |
| $\alpha_\text{Home}$ | Norm(0.0, 0.01) |
| $\alpha_\text{Work}$ | Norm(0.0, 0.01) |
| $\alpha_\text{Sch}$ | Norm(0.0, 0.01) |

## Distance function

We combine the simulated incidence report across age bins. We then assume
that total admissions in the weekly NHSN data counts are Poisson distributed according to the simulation. We
take the negative log likelihood score as our distance measure.

# Results

```{python}
#| echo: false
from abmwrappers.experiment_class import Experiment

experiment = Experiment(img_file="../experiment_history.pkl")
steps = len(experiment.tolerance_dict)
print(experiment)
```

## Simulation visualizations

```{python}
#| echo: false
import seaborn as sns
import matplotlib.pyplot as plt
import polars as pl

max_target = experiment.tolerance_dict[steps - 1]

# For azure implementations, use default blob container read:
if experiment.azure_batch:
    simulations = experiment.read_results(filename="simulations", verbose = False)
    distances = experiment.read_results(filename="distances",verbose=False)
# For local implementations, account for relative path of docs:
else:
    simulations = experiment.read_results(filename="simulations", input_dir ="../data")
    distances = experiment.read_results(filename="distances", input_dir ="../data")

inputs = [experiment.simulation_bundles[key].accepted for key in range(steps)]
inputs = pl.concat(inputs)
inputs = inputs.with_columns(
    ((pl.col("burn_in_period") // 7) * 7
    ).alias("burn_in_period")
)

simulations = simulations.join(inputs, on="simulation", how="inner")

simulations = simulations.with_columns(
    (pl.col("t") + pl.col("burn_in_period")).cast(pl.Int64).alias("t")
).filter(pl.col("t") >= 0)

posterior_sims=distances.sort("distance").filter(pl.col("distance")<max_target).join(simulations, on="simulation", how="inner")
print(f"Showing {posterior_sims.select(pl.n_unique('simulation')).item()} accepted simulations from last step below threshold {max_target}")
sns.lineplot(posterior_sims, x="t", y="count", estimator="median", errorbar=lambda x: (x.quantile(0.025), x.quantile(0.975)))
sns.lineplot(posterior_sims, x="t", y="count", estimator="median", errorbar=lambda x: (x.quantile(0.25), x.quantile(0.75)))
# sns.lineplot(posterior_sims, x="t", y="count",hue="distance", units="simulation", estimator=None)
sns.scatterplot(experiment.target_data, x = "t", y="total_admissions",zorder=10)
plt.show()
```

## Parameter posterior visualizations

The following plot shows the priors (blue histograms) and posteriors (orange histograms) for the 6 parameters fitted in the calibration process.
```{python}
#| echo: false
#| fig-width: 5
#| fig-height: 6
# Create a "long" form of the dataset
# as opposed to one column for each parameter
include_steps = list(experiment.tolerance_dict.keys())
include_steps.extend([experiment.current_step])

sims = []
for step in include_steps:
    sims.extend(
        [
            i + experiment.n_simulations * step
            for i in range(experiment.n_simulations)
        ]
    )
input_data = experiment.collect_inputs(sims).with_columns(
    pl.col("simulation")
    .map_elements(experiment.step_from_index, return_dtype=pl.Int64)
    .alias("step")
)

id_cols = ["simulation", "step"]
parameters = input_data.drop(
    id_cols + [experiment.seed_variable_name]
).columns
input_data_long = input_data.select(id_cols + parameters).unpivot(
    index=id_cols, variable_name="parameter"
)
input_data_long_prior_post = input_data_long.filter(
    pl.col("step").is_in([include_steps[0], include_steps[-1]])
)
# Plot the posteriors and priors
g = sns.FacetGrid(input_data_long_prior_post, col="parameter", hue="step", col_wrap=1, sharex=False, sharey=False, height = 1.5, aspect = 3)
g.map_dataframe(sns.histplot, x="value", fill=True, stat="density", binwidth = 0.01)
plt.show()
```

The next plot shows scatterplots illustrating pair-wise correlations of the posterior distributions of each parameter. (The histograms on the diagonal are the same univariate posteriors as plotted in the figure above.)

```{python}
#| echo: false
#| fig-width: 6.5
#| fig-height: 6.5
# restrict only to posteriors; exclude step == 0 (the priors)
input_data_post = input_data.filter(pl.col("step") == include_steps[-1])
# make the plot
g2 = sns.PairGrid(data=input_data_post.drop(id_cols + [experiment.seed_variable_name]))
g2.map_diag(sns.histplot)
g2.map_lower(sns.scatterplot)
# Hide the upper panels
for i in range(len(g2.axes)):
    for j in range(len(g2.axes)):
        if j > i:  # Upper triangle
            ax = g2.axes[i, j]
            ax.set_visible(False)
# Rotate the x-axis and y-axis labels
for ax in g2.axes.flatten():
    ax.xaxis.label.set_rotation(30)
    ax.yaxis.label.set_rotation(30)
    ax.xaxis.label.set_ha('right')
    ax.yaxis.label.set_ha('right')
plt.tight_layout()
plt.subplots_adjust(bottom=0.3, left=0.3)
plt.show()
```

The final plot shows for each variable how the inferred distribution changes across steps, with the top row of panels corresponding to the priors and the bottom row of panels corresponding to the posteriors plotted above.
```{python}
#| echo: false
#| fig-width: 6.5
#| fig-height: 6.5
# Plot how the distributions have changed
# for each parameter step-by-step
facet_by=["parameter", "step"]
step_aspect = facet_by.index("step")
sharex = ["row", "col"][step_aspect]
plt.rcParams.update({
    'font.size': 8,           # Default text size
    'axes.titlesize': 8,      # Panel titles
    'axes.labelsize': 8,      # Axis labels
    'xtick.labelsize': 8,     # X tick labels
    'ytick.labelsize': 8,     # Y tick labels
    'legend.fontsize': 8      # Legend text
})
g3 = sns.FacetGrid(input_data_long, col=facet_by[0], row=facet_by[1], sharex=sharex, sharey=True, height = 1, aspect = 1)
g3.map_dataframe(sns.histplot, x="value", fill=True, stat="density", binwidth = 0.01)
g3.set_titles("")
# Add column labels (parameter names) above each column
for col_idx, param in enumerate(input_data_long["parameter"].unique()):
    # Place title above the top axis in each column
    ax = g3.axes[0, col_idx]
    ax.set_title(param, fontsize=8, pad=20, rotation=30, ha='left')
# Add row labels (step values) to the right of each row
for row_idx, step in enumerate(input_data_long["step"].unique()):
    # Place label to the right of the last axis in each row
    ax = g3.axes[row_idx, -1]
    ax.annotate(
        f"Step: {step}",
        xy=(1.05, 0.5),
        xycoords='axes fraction',
        ha='left',
        va='center',
        fontsize=8,
        rotation=90
    )
plt.subplots_adjust(bottom=0.1, left=0.1, top=0.7, right=0.7, wspace=0.2, hspace = 0.2)
plt.show()
```

Scenario plotting
```{python}
# import os
# import json
# from abmwrappers import utils
# experiment = Experiment(img_file="../data/experiment_history.pkl")
# scenario_data = experiment.read_results(filename="scenarios", input_dir ="../data")
# scenarios_dir = "../scenarios"
# parameters = []
# for scenario in os.listdir(scenarios_dir):
#     with open("../input/griddle.json", "r") as fp:
#         raw_griddle = json.load(fp)
    
#     parameter_dict = {}
#     for key in raw_griddle["parameters"].keys():
#         subexperiment_params = os.path.join(
#             scenarios_dir, scenario, "input", "base.json"
#         )
#         with open(subexperiment_params, "r") as fp:
#             subexperiment_params_dict = json.load(fp)
#         flattened_dict = utils.flatten_dict(subexperiment_params_dict)
#         for k in flattened_dict.keys():
#             if "UpdatedIsolationGuidance" in k:
#                 adherence = flattened_dict["guidance_policy>>>UpdatedIsolationGuidance>>>policy_adherence"]
#                 if adherence == 0:
#                     parameter_dict["Guidance"] = "No Guidance"
#                     parameter_dict["Policy Adherence"] = adherence
#                 else:
#                     parameter_dict["Guidance"] = "Updated"
#                     parameter_dict["Policy Adherence"] = adherence
#                 break
#             elif "PreviousIsolationGuidance" in k:
#                 adherence = flattened_dict["guidance_policy>>>PreviousIsolationGuidance>>>policy_adherence"]
#                 parameter_dict["Guidance"] = "Previous"
#                 parameter_dict["Policy Adherence"] = adherence
#                 break 
#     parameter_dict["scenario"] = int(scenario.split("=")[-1])
#     parameter_dict["burn_in_period"] = subexperiment_params_dict["burn_in_period"]
#     parameters.append(parameter_dict)
# scenario_data = scenario_data.join(parameter_df, on="scenario")

# target_data = pd.read_csv(
#     "experiments/simple-fits/wyoming-incidence/input/target_data.csv"
# )
# scenario_data["burn_in_period"] = (scenario_data["burn_in_period"] // 7) * 7
# scenario_data["t_adjusted"] = (scenario_data["t_upper"] + scenario_data["burn_in_period"]).astype(int)
# scenario_data = scenario_data[scenario_data["t_adjusted"] >= 0]

# policy_adherence_levels = scenario_data["Policy Adherence"].unique()
# policy_adherence_levels = policy_adherence_levels[policy_adherence_levels != 0]
# num_levels = len(policy_adherence_levels)

# fig, axes = plt.subplots(
#     nrows=1,
#     ncols=num_levels,
#     figsize=(10, 6 * num_levels),
#     sharex=True,
#     sharey=True,
# )

# if num_levels == 1:
#     axes = [axes]  # Ensure axes is iterable for a single subplot


# for ax, level in zip(axes, policy_adherence_levels):
#     subset = scenario_data[(scenario_data["Policy Adherence"] == level) | (scenario_data["Policy Adherence"] == 0)]
#     sns.lineplot(
#         subset,
#         x="t_adjusted",
#         y="count",
#         hue="Guidance",
#         estimator="median",
#         errorbar=lambda x: (x.quantile(0.25), x.quantile(0.75)),
#         ax = ax,
#         legend=True,  # Show legend for this plot
#     )
#     sns.lineplot(
#         subset,
#         x="t_adjusted",
#         y="count",
#         hue="Guidance",
#         estimator="median",
#         errorbar=lambda x: (x.quantile(0.025), x.quantile(0.975)),
#         ax = ax,
#         legend=False,  # Show legend for this plot
#     )

#     sns.scatterplot(target_data, x="t", y="total_admissions", ax = ax, zorder=10, label = "Target Data", legend = True)
#     ax.set_title(f"Policy Adherence: {level}")
#     ax.set_xlabel("Time")
#     ax.set_ylabel("Hospitalizations")

# plt.show()

```

# Additional resources

## Citations
1. Chen et al., SARS-CoV-2 shedding dynamics across the respiratory tract, sex, and disease severity for adult and pediatric COVID-19. eLife. 2021. DOI: 10.7554/eLife.70458
2. Hladish et al. Evaluating targeted COVID-19 vaccination strategies with agent-based modeling. PLoS Comput Biol. 2024. DOI: 10.1371/journal.pcbi.1012128
3. Whitaker et al. Variant-Specific symptoms of COVID-19 in a study of 1,542,510 adults in England. Nat Comm. 2022. DOI: 10.1038/s41467-022-34244-2
4. Yadav et al. Association between patient-report onset-to-door time and mortality in patients hospitalized with COVID-19 disease. Am J Emerg Med. 2023. DOI: 10.1016/j.ajem.2023.11.044
