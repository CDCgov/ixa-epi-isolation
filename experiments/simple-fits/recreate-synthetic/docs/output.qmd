---
title: "Fit to synthetic hospitalization data report"
author: "Will Koval (AD71@cdc.gov, CDC/ORR/CFA)"
format: pdf
toc: true
number-sections: true
execute:
    warning: false
jupyter: python3
---

# Purpose

Proof-of-concept experiment to test the calibration routine. In this experiment, the model is calibrated to synthetic data generated from the same model. Because the underlying data generating process is the same, it should be possible for the calibrated model to capture the dynamics of the synthetic data.

# Methods

## Data

Data are generated by the current release build using the `../input/base.json`. A target data
file is created by determining the number of prevalent hospitalizations for pediatric cases (ages 0-17) and
adult cases (ages 18+) for each day.

## Parameters

| Parameter name | Description |
| :------------: | ----------- |
| `initial_incidence` | Initial fraction of population infectious |
| `initial_recovered` | Initial fraction of population immune to infection |
| `proportion_asymptomatic` | The fraction of new cases that will never develop symptoms |
| `relative_infectiousness_asymptomatics` | Multiplier for the relative infectiousness of asymptomatic infectious individuals compared to symptomatics |
| `Home.alpha` | Property of `Home` settings that modulates density-dependence |
| `Workplace.alpha` | Property of `Workplace` settings that modulates density-dependence |
| `School.alpha` | Property of `School` settings that modulates density-dependence |
| `CensusTract.alpha` | Property of `CensusTract` settings that modulates density-dependence |
| `symptom_progression_library` | Rates of symptom onset and recovery for symptom categories |
| `mean_delay_to_hospitalization` | Mean time from symptom onset to hospitalization |
| `mean_duration_of_hospitalization` | Mean time that hospitalized individuals stay in the hospital before recovery |
| `age_groups.min` | Age group lower bound associated with hospitalization risk values |
| `age_groups.probability` | Probability that symptomatic individuals become hospitalized for a given age group |
| `infectiousness_rate_fn` | Function to determine the rate at which infectious individuals generate infection attempts |

We assume no interventions, so parameters like facemask efficacy and the guidance policy are not used.

Simulation run time is set for 200 days.

### Fixed parameter values

| Parameter | Value | Source |
| :-------: | :---: | ------ |
| `initial_incidence` | 0.01 | Small initial incidence |
| `initial_recovered` | 0.0 | Completely susceptible population |
| `proportion_asymptomatic` | 0.45 | Alpha variant estimate, Whitaker et al. 2022 Nat Comm. |
| `relative_infectiousness_asymptomatics` | 0.5 | Assumption that asymptomatics are half as infectious|
| `Home.alpha` | 0.05 | Assume small density-dependence effect at home |
| `Workplace.alpha` | 0.0 | Assume no density-dependence in workplace |
| `School.alpha` | 0.1 | Assume moderate density-dependence effect in school |
| `CensusTract.alpha` | 0.0 | Assume no density-dependence in community |
| `symptom_progression_library` | Category-dependent Weibull | Use posteriors from viral-load isolation gudiance |
| `mean_delay_to_hospitalization` | 5.7 | Mean delay from Yadav et al. 2023 Am J Emerg Med |
| `mean_duration_of_hospitalization` | 8.0 | Approximated during GCM experiments using NHCS data |
| `age_groups.min` | 0, 18 | Split population into pediatric admissions and adult admissions |
| `age_groups.probability` | 0.075, 0.15 | Assumed to be lower than Delta (0.456) and Omicron (0.373) estimates from vaccinated populations Menni et al Lancet |
| `infectiousness_rate_fn` | Category-dependent triangle VL | Use posteriors from isolation guidance model|
| `infectiousness_rate_fn.scale` | 0.01 | Re-scale infectiousness to reduce $R_0$ |

### Fitted parameter values

We are attempting to recapture the target input values of the initial simulation by fitting
the scale of empirical infectiousness rate distributions, the density-dependence of at-home
and in-school transmission, and the proportion of infections that develop symptoms.

| Parameter | Prior | Source |
| :-------: | :---: | ------ |
| `infectiousness_rate_fn.scale` | Uniform(0.0, 0.2) | Aiming to re-capture 0.06 |
| `proportion_asymptomatic` | Uniform(0.0, 1.0) | Aiming to recapture 0.45 |
| `Home.alpha` | Uniform(0.0, 0.2) | Aiming to recapture 0.05 |
| `School.alpha` | Uniform(0.0, 0.2) | Aiming to recapture 0.1 |

Ideally the posteriors estimates should distinguish between the alpha values for `Home` and `School` settings.

We use uniform priors to let the high-quality synthetic data drive calibration.
Perturbation kernels will make small changes to the parameter sets using random walks.

| Parameter | Perturbation |
| :-------: | :---: |
| `infectiousness_rate_fn.scale` | Norm(0.0, 0.01) |
| `proportion_asymptomatic` | Norm(0.0, 0.05) |
| `Home.alpha` | Norm(0.0, 0.01) |
| `School.alpha` | Norm(0.0, 0.01) |

The standard deviations of the pertubation kernels should approximately scale with the width
of the priors.

## Distance function

We split the simulated prevalence report into pediatric and adult hospital occupancy. We then assume
that each group in the synthetic data is Poisson distributed according to the simulation. We
take the sum of the two negative log likelihood scores as our distance measure.

# Results

Load the experiment history file if available

```{python}
#| echo: false
from abmwrappers.experiment_class import Experiment
import yaml

experiment = Experiment(img_file="../data/experiment_history.pkl")

with open("../input/config.yaml", "r") as f:
    config = yaml.safe_load(f)

sub_experiment_name = config["local_path"]["sub_experiment_name"]

experiment.sub_experiment_name = sub_experiment_name

for step, tolerance in experiment.tolerance_dict.items():
    print(f"Step {step} filtered for distances below {tolerance}.")
```

## Simulation visualizations

```{python}
#| echo: false
#| output: false
import seaborn as sns
import matplotlib.pyplot as plt
import polars as pl

# For azure implementations, use default blob container read:
if experiment.azure_batch:
    simulations = experiment.read_results(filename="simulations")
    distances = experiment.read_results(filename="distances")
# For local implementations, account for relative path of docs:
else:
    simulations = experiment.read_results(filename="simulations", input_dir ="../data")
    distances = experiment.read_results(filename="distances", input_dir ="../data")
```

The following epidemic curve shows the simulated "observed" target data (points) and the median (solid line) and 95% confidence interval for the best-fit simulations, all stratified by adult versus pediatric.

```{python}
#| echo: false
# restrict to simulations below the distance threshold
steps = len(experiment.tolerance_dict)
max_target = experiment.tolerance_dict[steps - 1]

best_sims=distances.sort("distance").filter(pl.col("distance")<max_target).join(simulations, on="simulation", how="inner")
print(f"Showing {best_sims.select(pl.n_unique('simulation')).item()} accepted simulations from last step below threshold {max_target}")

sns.lineplot(best_sims, x="t", y="count", hue="pediatric", estimator="median", errorbar=lambda x: (x.quantile(0.025), x.quantile(0.975)))
sns.scatterplot(experiment.target_data, x = "t", y="count",hue="pediatric",zorder=10)
plt.ylabel("prevalent hospitalizations")
plt.show()
```

The next plot is based on the same best-fit simulations as above, but now the individual fitted simulations are plotted and are shaded based on their distance from the target data.

```{python}
#| echo: false
sns.lineplot(best_sims.filter(pl.col("pediatric") == False), x="t", y="count",hue="distance", units="simulation", estimator=None)
sns.lineplot(best_sims.filter(pl.col("pediatric") == True), x="t", y="count",hue="distance", units="simulation", estimator=None)
sns.scatterplot(experiment.target_data, x = "t", y="count",hue="pediatric",zorder=10)
plt.show()
```

## Parameter posterior visualizations

The next plot shows the priors (light-shaded histograms) and posteriors (dark-shaded histograms) for the 4 parameters fitted in the calibration process. Briefly, the calibration appears to have worked fairly well to capture the "true" scale parameter and less well at capturing the other parameters, especially the value of alpha in school settings.
```{python}
#| echo: false
#| fig-width: 5
#| fig-height: 6

import matplotlib.pyplot as plt
import polars as pl
import seaborn as sns

# Determine and extract the simulation inputs and steps to use
include_steps = [experiment.current_step]

include_steps.extend([0])

sims = []
for step in include_steps:
    sims.extend(
        [
            i + experiment.n_simulations * step
            for i in range(experiment.n_simulations)
        ]
    )

input_data = experiment.collect_inputs(sims).with_columns(
    pl.col("simulation")
    .map_elements(experiment.step_from_index, return_dtype=pl.Int64)
    .alias("step")
)

# Create a "long" form of the dataset
# as opposed to one column for each parameter
id_cols = ["simulation", "step"]
parameters = input_data.drop(
    id_cols + [experiment.seed_variable_name]
).columns

input_data_long = input_data.select(id_cols + parameters).unpivot(
    index=id_cols, variable_name="parameter"
)

# Plot the posteriors and priors
g = sns.displot(
    data=input_data_long, x="value", col="parameter", hue="step",
    col_wrap=1, kind="hist", height = 1.5, aspect = 3,
    facet_kws={"sharex": False, "sharey": False},
    fill=True, stat="density", binwidth = 0.01, common_bins=False
)

plt.show()

```

The final plot shows scatterplots illustrating pair-wise correlations of the posterior distributions of each parameter. (The histograms on the diagonal are the same univariate posteriors as plotted in the figure above.)
```{python}
#| echo: false
#| fig-width: 6.5
#| fig-height: 6.5
# restrict only to posteriors; exclude step == 0 (the priors)
input_data_2 = input_data.filter(pl.col("step") == 2)

# make the plot
g2 = sns.PairGrid(data=input_data_2.drop(id_cols + [experiment.seed_variable_name]))

g2.map_diag(sns.histplot)

g2.map_lower(sns.scatterplot)

# Hide the upper panels
for i in range(len(g2.axes)):
    for j in range(len(g2.axes)):
        if j > i:  # Upper triangle
            ax = g2.axes[i, j]
            ax.set_visible(False)

# Rotate the x-axis and y-axis labels
for ax in g2.axes.flatten():
    ax.xaxis.label.set_rotation(30)
    ax.yaxis.label.set_rotation(30)
    ax.xaxis.label.set_ha('right')
    ax.yaxis.label.set_ha('right')

plt.tight_layout()
plt.subplots_adjust(bottom=0.3, left=0.3)
plt.show()

```

# Additional resources

## Citations
